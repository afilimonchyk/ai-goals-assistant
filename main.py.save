from fastapi import FastAPI, HTTPException  # Импортируем FastAPI и HTTPException для обработки ошибок
from pydantic import BaseModel            # Импортируем BaseModel для описания структуры входных данных
import openai                             # Импортируем библиотеку openai

# Задай свой API-ключ (для безопасности можно потом использовать переменные окружения)
openai.api_key = "YOUR_API_KEY"

app = FastAPI()  # Создаем экземпляр приложения

# Создаем модель данных для входящего запроса
class Prompt(BaseModel):
    prompt: str  # Ожидается, что пользователь пришлет строку с запросом

# Новый маршрут для отправки запроса к OpenAI
@app.post("/ask")
async def ask_openai(prompt: Prompt):
    """
    Эта функция принимает запрос с полем prompt, отправляет его к OpenAI и возвращает ответ модели.
    """
    try:
        # Отправляем запрос к API OpenAI, используя модель GPT-3.5 Turbo
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt.prompt}
            ]
        )
        # Извлекаем текст ответа
        answer = response.choices[0].message.content
        return {"answer": answer}
    except Exception as e:
        # Если что-то пошло не так, возвращаем ошибку
        raise HTTPException(status_code=500, detail=str(e))
from fastapi import FastAPI  # Импортируем класс FastAPI из библиотеки fastapi

app = FastAPI()  # Создаем экземпляр приложения

@app.get("/")  # Декоратор, указывающий, что функция ниже обрабатывает GET-запросы по адресу "/"
def read_root():
    return {"Hello": "World"}  # Функция возвращает простой JSON-ответ
